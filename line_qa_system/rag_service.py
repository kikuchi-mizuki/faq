"""
RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚µãƒ¼ãƒ“ã‚¹
AIè¦ç´„æ©Ÿèƒ½ã®å®Ÿè£…
"""

import os
import json
import time
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import structlog

import psycopg2
from psycopg2 import pool
from psycopg2.extras import RealDictCursor

# æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè»½é‡åŒ–ç‰ˆï¼‰
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None

import google.generativeai as genai
from google.oauth2.service_account import Credentials
import gspread

from .config import Config
from .utils import normalize_text

logger = structlog.get_logger(__name__)


class RAGService:
    """RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        try:
            print("=" * 60)
            print("ğŸ“ RAGServiceã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("RAGServiceã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            self.embedding_model = None
            self.db_connection = None
            self.db_pool = None  # æ¥ç¶šãƒ—ãƒ¼ãƒ«
            self.is_enabled = False

            # è¨­å®šã®èª­ã¿è¾¼ã¿
            self.gemini_api_key = os.getenv('GEMINI_API_KEY')
            self.database_url = os.getenv('DATABASE_URL')
            self.embedding_model_name = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-MiniLM-L6-v2')
            self.vector_dimension = int(os.getenv('VECTOR_DIMENSION', '384'))
            self.similarity_threshold = float(os.getenv('SIMILARITY_THRESHOLD', '0.6'))
            self.gemini_model = None

            print(f"âœ… GEMINI_API_KEYè¨­å®š: {'ã‚ã‚Š' if self.gemini_api_key else 'ãªã—'}")
            print(f"âœ… DATABASE_URLè¨­å®š: {'ã‚ã‚Š' if self.database_url else 'ãªã—'}")
            logger.warning("RAGServiceã®è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            # ã‚·ãƒ³ãƒ—ãƒ«ãªåˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯
            self._initialize_rag_service()

            # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
            print(f"ğŸ¯ RAGServiceåˆæœŸåŒ–å®Œäº†: is_enabled={self.is_enabled}")
            print(f"ğŸ¯ Geminiãƒ¢ãƒ‡ãƒ«: {self.gemini_model is not None}")
            print(f"ğŸ¯ DBæ¥ç¶šãƒ—ãƒ¼ãƒ«: {self.db_pool is not None}")
            print("=" * 60)
            logger.warning(f"RAGServiceåˆæœŸåŒ–å®Œäº†: is_enabled={self.is_enabled}")

        except Exception as e:
            print(f"âŒ RAGServiceã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error("RAGServiceã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            self.is_enabled = False

    def __del__(self):
        """ãƒ‡ã‚¹ãƒˆãƒ©ã‚¯ã‚¿ - æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚º"""
        try:
            if self.db_pool:
                self.db_pool.closeall()
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ã‚¯ãƒ­ãƒ¼ã‚ºã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"âš ï¸ æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®ã‚¯ãƒ­ãƒ¼ã‚ºä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    def _initialize_rag_service(self):
        """RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        try:
            print("ğŸ”§ RAGã‚µãƒ¼ãƒ“ã‚¹ã®å†…éƒ¨åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®åˆæœŸåŒ–ã‚’è©¦è¡Œ
            print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è©¦è¡Œã—ã¦ã„ã¾ã™...")
            database_success = self._try_database_connection()
            print(f"ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®çµæœ: {database_success}")
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®çµæœ: {database_success}")

            if database_success:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸå ´åˆã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸãŸã‚ã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸãŸã‚ã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                self._initialize_full_rag()
            else:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸå ´åˆã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–
                print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸãŸã‚ã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸãŸã‚ã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                self._initialize_fallback_rag()

        except Exception as e:
            print(f"âŒ RAGã‚µãƒ¼ãƒ“ã‚¹ã®å†…éƒ¨åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error("RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e))
            self.is_enabled = False

    def _initialize_fallback_rag(self):
        """ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆpgvectorãªã—ï¼‰"""
        try:
            print("ğŸ”§ ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            # Gemini APIã®ã¿ã‚’ä½¿ç”¨ã—ãŸRAGæ©Ÿèƒ½
            if self.gemini_api_key:
                print("ğŸ”‘ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
                genai.configure(api_key=self.gemini_api_key)

                # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰
                try:
                    # gemini-2.0-flash-expã‚’ç›´æ¥ä½¿ç”¨ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã¯é…ã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                    print("ğŸ¤– Geminiãƒ¢ãƒ‡ãƒ« 'gemini-2.0-flash-exp' ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
                    self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
                    print("âœ… RAG: gemini-2.0-flash-expã‚’ä½¿ç”¨ã—ã¾ã™")
                    logger.info("RAG: gemini-2.0-flash-expã‚’ä½¿ç”¨ã—ã¾ã™")

                except Exception as model_error:
                    print(f"âŒ RAG: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {model_error}")
                    logger.error("RAG: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(model_error))
                    self.gemini_model = None
                    logger.warning("RAG: Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    self.is_enabled = False
                    return

                print("âœ… ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                self.is_enabled = True
                print(f"ğŸ¯ is_enabled ã‚’ True ã«è¨­å®šã—ã¾ã—ãŸ")
            else:
                print("âŒ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                logger.warning("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
                self.is_enabled = False
        except Exception as e:
            print(f"âŒ ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error("ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e))
            logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
            self.is_enabled = False

    def _try_database_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è©¦è¡Œï¼ˆæˆåŠŸ/å¤±æ•—ã‚’è¿”ã™ï¼‰"""
        # DATABASE_URLãŒè¨­å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯å³åº§ã«Falseã‚’è¿”ã™
        if not self.database_url:
            print("âš ï¸ DATABASE_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ä»£æ›¿RAGãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
            logger.warning("DATABASE_URLãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False

        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šä»˜ãã§æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆï¼ˆ10ç§’ã«å»¶é•·ï¼‰
            # Railwayç’°å¢ƒã§ã¯ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶ãŒã‚ã‚‹ãŸã‚
            print("ğŸ”Œ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
            self.db_pool = pool.SimpleConnectionPool(
                minconn=1,
                maxconn=5,
                dsn=self.database_url,
                connect_timeout=10
            )
            # åˆæœŸæ¥ç¶šãƒ†ã‚¹ãƒˆç”¨
            self.db_connection = self.db_pool.getconn()
            print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")

            # pgvectoræ‹¡å¼µã®ç¢ºèªï¼ˆç°¡ç•¥ç‰ˆï¼‰
            with self.db_connection.cursor() as cursor:
                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®ç¢ºèªï¼ˆè©³ç´°ãªãƒã‚§ãƒƒã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦é«˜é€ŸåŒ–ï¼‰
                cursor.execute("SELECT * FROM pg_available_extensions WHERE name = 'vector';")
                available_extensions = cursor.fetchall()

                if not available_extensions:
                    print("âš ï¸ pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä»£æ›¿RAGãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
                    logger.warning("pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä»£æ›¿RAGãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                    return False

                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–ã‚’è©¦è¡Œ
                cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                self.db_connection.commit()
                print("âœ… pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
                logger.info("pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")

            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
            print("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¦ã„ã¾ã™...")
            self.create_tables()
            print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸ")
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨pgvectorã®ä¸¡æ–¹ãŒæˆåŠŸã—ãŸãŸã‚Trueã‚’è¿”ã—ã¾ã™")

            # åˆæœŸæ¥ç¶šã‚’è¿”å´
            self.db_pool.putconn(self.db_connection)
            self.db_connection = None

            return True

        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e), exc_info=True)
            if self.db_connection and self.db_pool:
                self.db_pool.putconn(self.db_connection)
            self.db_connection = None
            self.db_pool = None
            return False

    def _initialize_full_rag(self):
        """å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–"""
        try:
            # è»½é‡èµ·å‹•ãƒ¢ãƒ¼ãƒ‰ã®ç¢ºèªï¼ˆç’°å¢ƒå¤‰æ•°ã§RAGæ©Ÿèƒ½ã‚’å®Œå…¨ã«ç„¡åŠ¹åŒ–å¯èƒ½ï¼‰
            rag_lightweight_mode = os.getenv('RAG_LIGHTWEIGHT_MODE', 'false').lower() == 'true'

            if rag_lightweight_mode:
                print("âš¡ RAGè»½é‡ãƒ¢ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ã§ã™ã€‚Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                logger.warning("RAGè»½é‡ãƒ¢ãƒ¼ãƒ‰: Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                # ä»£æ›¿RAGæ©Ÿèƒ½ã«åˆ‡ã‚Šæ›¿ãˆ
                self._initialize_fallback_rag()
                return

            # Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            if SENTENCE_TRANSFORMERS_AVAILABLE and NUMPY_AVAILABLE:
                print(f"ğŸ“š Embeddingãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {self.embedding_model_name}")
                print("âš ï¸ ã“ã®å‡¦ç†ã«ã¯æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™...")
                logger.info(f"Embeddingãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {self.embedding_model_name}")
                self.embedding_model = SentenceTransformer(self.embedding_model_name)
                print("âœ… Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
                logger.info("Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                logger.warning("sentence-transformersã¾ãŸã¯numpyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                logger.warning("å®Œå…¨RAGæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ããªã„ãŸã‚ã€ä»£æ›¿RAGæ©Ÿèƒ½ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™")
                # ä»£æ›¿ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ
                self._initialize_fallback_rag()
                return

            # Gemini APIã®åˆæœŸåŒ–
            if self.gemini_api_key:
                genai.configure(api_key=self.gemini_api_key)

                # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
                try:
                    models = genai.list_models()
                    available_models = [model.name for model in models if 'generateContent' in model.supported_generation_methods]
                    logger.info(f"RAGåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {available_models[:5]}")  # æœ€åˆã®5ã¤ã®ã¿ãƒ­ã‚°

                    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠï¼ˆ2.0ã‚’å„ªå…ˆï¼‰
                    if 'models/gemini-2.0-flash-001' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-001')
                        logger.info("RAG: gemini-2.0-flash-001ã‚’ä½¿ç”¨ã—ã¾ã™")
                    elif 'models/gemini-flash-latest' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-flash-latest')
                        logger.info("RAG: gemini-flash-latestã‚’ä½¿ç”¨ã—ã¾ã™")
                    elif 'models/gemini-2.5-flash' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
                        logger.info("RAG: gemini-2.5-flashã‚’ä½¿ç”¨ã—ã¾ã™")
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')
                        logger.info("RAG: gemini-1.5-flash-latestã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")

                except Exception as model_error:
                    logger.warning("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™", error=str(model_error))
                    self.gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')

                logger.info("Gemini APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

            self.is_enabled = True
            logger.info("å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error("å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e), exc_info=True)
            self.is_enabled = False

    def create_tables(self):
        """å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
        if not self.db_connection:
            logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        try:
            with self.db_connection.cursor() as cursor:
                # æ–‡æ›¸ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS documents (
                        id SERIAL PRIMARY KEY,
                        source_type VARCHAR(50) NOT NULL,
                        source_id VARCHAR(100) NOT NULL,
                        title TEXT,
                        content TEXT NOT NULL,
                        chunk_index INTEGER DEFAULT 0,
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """)
                
                # ãƒ™ã‚¯ãƒˆãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS document_embeddings (
                        id SERIAL PRIMARY KEY,
                        document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
                        embedding vector(%s),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """, (self.vector_dimension,))
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
                cursor.execute("""
                    CREATE INDEX IF NOT EXISTS idx_document_embeddings_vector 
                    ON document_embeddings USING ivfflat (embedding vector_cosine_ops);
                """)
                
                self.db_connection.commit()
                logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
                return True
                
        except Exception as e:
            logger.error("ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return False

    def add_document(self, source_type: str, source_id: str, title: str, content: str, metadata: Dict[str, Any] = None, generate_embeddings: bool = True) -> bool:
        """æ–‡æ›¸ã‚’è¿½åŠ 

        Args:
            source_type: ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
            source_id: ã‚½ãƒ¼ã‚¹ID
            title: ã‚¿ã‚¤ãƒˆãƒ«
            content: å†…å®¹
            metadata: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
            generate_embeddings: Embeddingã‚’å³åº§ã«ç”Ÿæˆã™ã‚‹ã‹ï¼ˆFalse=å¾Œã§ç”Ÿæˆï¼‰
        """
        if not self.is_enabled:
            logger.warning("RAGServiceãŒç„¡åŠ¹ã§ã™")
            return False

        # ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã®å ´åˆã€æ–‡æ›¸è¿½åŠ ã¯åˆ©ç”¨ã§ããªã„
        if not self.db_pool or not self.embedding_model:
            logger.info("ä»£æ›¿RAGæ©Ÿèƒ½ã§ã¯æ–‡æ›¸è¿½åŠ ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆãƒ™ã‚¯ãƒˆãƒ«DBæœªæ¥ç¶šï¼‰")
            return False

        conn = None
        try:
            # æ–‡æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = self._split_text(content)
            logger.info(f"æ–‡æ›¸ã‚’{len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")

            document_ids = []

            # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‹ã‚‰æ¥ç¶šã‚’å–å¾—
            conn = self.db_pool.getconn()
            with conn.cursor() as cursor:
                # 1. ã¾ãšå…¨æ–‡ã‚’ä¿å­˜ï¼ˆGemsæ–¹å¼ã®å­¦ç¿’ç”¨ï¼‰
                cursor.execute("""
                    INSERT INTO documents (source_type, source_id, title, content, full_content, chunk_index, is_full_text_chunk, metadata)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                    RETURNING id;
                """, (source_type, source_id, title, content[:1000], content, -1, True, json.dumps(metadata or {})))

                full_text_doc_id = cursor.fetchone()[0]
                logger.info(f"å…¨æ–‡ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {source_type}/{source_id}, ã‚µã‚¤ã‚º={len(content)}æ–‡å­—")

                # 2. ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ï¼ˆãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ç”¨ï¼‰
                for i, chunk in enumerate(chunks):
                    # æ–‡æ›¸ã‚’ä¿å­˜
                    cursor.execute("""
                        INSERT INTO documents (source_type, source_id, title, content, full_content, chunk_index, is_full_text_chunk, metadata)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                        RETURNING id;
                    """, (source_type, source_id, title, chunk, content, i, False, json.dumps(metadata or {})))

                    document_id = cursor.fetchone()[0]
                    document_ids.append(document_id)

                    # Embeddingã‚’å³åº§ã«ç”Ÿæˆã™ã‚‹å ´åˆã®ã¿
                    if generate_embeddings:
                        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
                        embedding = self._generate_embedding(chunk)

                        # ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜
                        embedding_str = '[' + ','.join(map(str, embedding.tolist())) + ']'
                        cursor.execute("""
                            INSERT INTO document_embeddings (document_id, embedding)
                            VALUES (%s, %s::vector);
                        """, (document_id, embedding_str))

                conn.commit()

                if generate_embeddings:
                    logger.info(f"æ–‡æ›¸ï¼ˆå…¨æ–‡+ãƒãƒ£ãƒ³ã‚¯ï¼‰ã¨Embeddingã‚’è¿½åŠ ã—ã¾ã—ãŸ: {source_type}/{source_id}, {len(chunks)}ãƒãƒ£ãƒ³ã‚¯")
                else:
                    logger.info(f"æ–‡æ›¸ï¼ˆå…¨æ–‡+ãƒãƒ£ãƒ³ã‚¯ï¼‰ã‚’è¿½åŠ ã—ã¾ã—ãŸï¼ˆEmbeddingã¯å¾Œã§ç”Ÿæˆï¼‰: {source_type}/{source_id}, {len(chunks)}ãƒãƒ£ãƒ³ã‚¯")

                return True

        except Exception as e:
            logger.error("æ–‡æ›¸è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e), exc_info=True)
            if conn:
                try:
                    conn.rollback()
                except:
                    pass
            return False
        finally:
            # æ¥ç¶šã‚’ãƒ—ãƒ¼ãƒ«ã«è¿”å´
            if conn and self.db_pool:
                self.db_pool.putconn(conn)

    def search_similar_documents(self, query: str, limit: int = 3) -> List[Dict[str, Any]]:
        """é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢"""
        print(f"ğŸ” search_similar_documents å‘¼ã³å‡ºã—: query='{query}'")
        logger.info(f"search_similar_documents å‘¼ã³å‡ºã—: query='{query}'")

        if not self.is_enabled:
            print("âŒ RAGServiceãŒç„¡åŠ¹ã§ã™")
            logger.warning("RAGServiceãŒç„¡åŠ¹ã§ã™")
            return []

        # ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã®å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯åˆ©ç”¨ã§ããªã„
        if not self.db_pool or not self.embedding_model:
            print(f"âš ï¸ DBæ¥ç¶šãƒ—ãƒ¼ãƒ«: {self.db_pool is not None}, Embeddingãƒ¢ãƒ‡ãƒ«: {self.embedding_model is not None}")
            logger.warning(f"ä»£æ›¿RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯: DBæ¥ç¶šãƒ—ãƒ¼ãƒ«={self.db_pool is not None}, Embeddingãƒ¢ãƒ‡ãƒ«={self.embedding_model is not None}")
            return []

        conn = None
        try:
            print("âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™")
            # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
            query_embedding = self._generate_embedding(query)
            print(f"âœ… ã‚¯ã‚¨ãƒªã®Embeddingã‚’ç”Ÿæˆã—ã¾ã—ãŸ: shape={query_embedding.shape if hasattr(query_embedding, 'shape') else 'N/A'}")

            # æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‹ã‚‰æ¥ç¶šã‚’å–å¾—
            conn = self.db_pool.getconn()
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
                embedding_str = '[' + ','.join(map(str, query_embedding.tolist())) + ']'

                # é¡ä¼¼åº¦æ¤œç´¢ï¼ˆé€šå¸¸ãƒãƒ£ãƒ³ã‚¯ã®ã¿å¯¾è±¡ - is_full_text_chunk=falseï¼‰
                print(f"ğŸ” é¡ä¼¼åº¦é–¾å€¤: {self.similarity_threshold}")
                cursor.execute("""
                    SELECT
                        d.id,
                        d.source_type,
                        d.source_id,
                        d.title,
                        d.content,
                        d.full_content,
                        d.metadata,
                        1 - (de.embedding <=> %s::vector) as similarity
                    FROM documents d
                    JOIN document_embeddings de ON d.id = de.document_id
                    WHERE d.is_full_text_chunk = FALSE
                    ORDER BY similarity DESC
                    LIMIT 10;
                """, (embedding_str,))

                all_results = cursor.fetchall()
                print(f"ğŸ” å…¨æ–‡æ›¸ã®é¡ä¼¼åº¦TOP10:")
                for i, row in enumerate(all_results[:5]):
                    print(f"  {i+1}. similarity={row['similarity']:.4f}, title={row['title'][:50]}")

                # é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                results = [r for r in all_results if r['similarity'] > self.similarity_threshold]
                print(f"âœ… é–¾å€¤ {self.similarity_threshold} ä»¥ä¸Š: {len(results)}ä»¶")

                # limitã§çµã‚‹ï¼ˆãŸã ã—source_idã”ã¨ã«1ä»¶ã®ã¿ï¼‰
                seen_source_ids = set()
                unique_results = []
                for r in results:
                    if r['source_id'] not in seen_source_ids:
                        seen_source_ids.add(r['source_id'])
                        unique_results.append(r)
                        if len(unique_results) >= limit:
                            break

                results = unique_results
                print(f"âœ… DBæ¤œç´¢çµæœï¼ˆæœ€çµ‚ã€é‡è¤‡é™¤å¤–ï¼‰: {len(results)}ä»¶")

                # è¾æ›¸å½¢å¼ã«å¤‰æ›ï¼ˆfull_contentã‚’ä½¿ç”¨ - Gemsæ–¹å¼ï¼‰
                documents = []
                for row in results:
                    documents.append({
                        'id': row['id'],
                        'source_type': row['source_type'],
                        'source_id': row['source_id'],
                        'title': row['title'],
                        'content': row['full_content'] if row['full_content'] else row['content'],  # å…¨æ–‡ã‚’å„ªå…ˆ
                        'metadata': row['metadata'],
                        'similarity': float(row['similarity'])
                    })

                print(f"ğŸ¯ é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¾ã—ãŸ: {len(documents)}ä»¶")
                logger.info(f"é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¾ã—ãŸ: {len(documents)}ä»¶")
                return documents

        except Exception as e:
            print(f"âŒ é¡ä¼¼æ–‡æ›¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error("é¡ä¼¼æ–‡æ›¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return []
        finally:
            # æ¥ç¶šã‚’ãƒ—ãƒ¼ãƒ«ã«è¿”å´
            if conn and self.db_pool:
                self.db_pool.putconn(conn)

    def generate_answer(self, query: str, context: str = "") -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆ"""
        if not self.gemini_api_key or not self.gemini_model:
            logger.warning("Gemini APIã‚­ãƒ¼ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚AIå›ç­”ç”Ÿæˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            prompt = self._build_prompt(query, context)
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—
            response = self.gemini_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1000,
                    temperature=0.7,
                )
            )
            
            answer = response.text
            logger.info("Gemini AIå›ç­”ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            return answer
            
        except Exception as e:
            logger.error("Gemini AIå›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    def _split_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # æ–‡ã®å¢ƒç•Œã§åˆ†å‰²
            if end < len(text):
                # æœ€å¾Œã®å¥ç‚¹ã‚’æ¢ã™
                last_period = text.rfind('ã€‚', start, end)
                if last_period > start:
                    end = last_period + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
            if start >= len(text):
                break
        
        return chunks

    def _generate_embedding(self, text: str):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        if not NUMPY_AVAILABLE:
            raise ValueError("numpyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è»½é‡åŒ–ç‰ˆã§ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
        
        if not self.embedding_model:
            raise ValueError("Embeddingãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
        normalized_text = normalize_text(text)
        
        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
        embedding = self.embedding_model.encode(normalized_text)
        
        return embedding

    def _build_context(self, documents: List[Dict[str, Any]]) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰ï¼ˆè‡ªç„¶ãªä¼šè©±ç”¨ã«ç°¡ç´ åŒ–ï¼‰"""
        # æ–‡æ›¸ã®å†…å®¹ã®ã¿ã‚’çµåˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚„é¡ä¼¼åº¦ãªã©ã®ãƒ¡ã‚¿æƒ…å ±ã¯å«ã‚ãªã„ï¼‰
        context_parts = []

        for doc in documents:
            # æ–‡æ›¸ã®å†…å®¹ã®ã¿ã‚’è¿½åŠ 
            context_parts.append(doc['content'])

        # æ”¹è¡Œã§åŒºåˆ‡ã£ã¦çµåˆ
        return "\n\n".join(context_parts)

    def _build_prompt(self, query: str, context: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        if context:
            return f"""
ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…ã§ã™ã€‚ä»¥ä¸‹ã®è³‡æ–™ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«è‡ªç„¶ãªä¼šè©±ã§ç­”ãˆã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{query}

ã€å‚è€ƒè³‡æ–™ã€‘
{context}

ã€å›ç­”ã®ãƒ«ãƒ¼ãƒ«ã€‘
- å‹é”ã«èª¬æ˜ã™ã‚‹ã‚ˆã†ã«ã€è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ç­”ãˆã‚‹
- ã€Œ1. çµè«–ã€ã€Œ2. æ‰‹é †ã€ãªã©ã®æ§‹é€ åŒ–ã•ã‚ŒãŸè¦‹å‡ºã—ã‚„ç•ªå·ä»˜ã‘ã¯ä½¿ã‚ãªã„
- ç°¡æ½”ã«ã€ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦å…·ä½“ä¾‹ã‚’æŒ™ã’ã‚‹
- å‚è€ƒè³‡æ–™ã®æƒ…å ±ã‚’åŸºã«å›ç­”ã™ã‚‹
- å›ç­”ã®æœ€å¾Œã«æ³¨æ„æ›¸ããªã©ã¯ä»˜ã‘ãªã„ï¼ˆã‚·ã‚¹ãƒ†ãƒ å´ã§è‡ªå‹•è¿½åŠ ã•ã‚Œã¾ã™ï¼‰
"""
        else:
            return f"""
ã‚ãªãŸã¯è¦ªã—ã¿ã‚„ã™ã„ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆæ‹…å½“è€…ã§ã™ã€‚è³ªå•ã«è‡ªç„¶ãªä¼šè©±ã§ç­”ãˆã¦ãã ã•ã„ã€‚

ã€è³ªå•ã€‘
{query}

ã€å›ç­”ã®ãƒ«ãƒ¼ãƒ«ã€‘
- å‹é”ã«èª¬æ˜ã™ã‚‹ã‚ˆã†ã«ã€è‡ªç„¶ã§è¦ªã—ã¿ã‚„ã™ã„å£èª¿ã§ç­”ãˆã‚‹
- ã€Œ1. çµè«–ã€ã€Œ2. æ‰‹é †ã€ãªã©ã®æ§‹é€ åŒ–ã•ã‚ŒãŸè¦‹å‡ºã—ã‚„ç•ªå·ä»˜ã‘ã¯ä½¿ã‚ãªã„
- ç°¡æ½”ã«ã€ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã™ã‚‹
- å¿…è¦ã«å¿œã˜ã¦å…·ä½“ä¾‹ã‚’æŒ™ã’ã‚‹
"""

    def health_check(self) -> bool:
        """RAGã‚µãƒ¼ãƒ“ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        return self.is_enabled and self.gemini_model is not None
