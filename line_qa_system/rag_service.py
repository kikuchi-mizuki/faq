"""
RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚µãƒ¼ãƒ“ã‚¹
AIè¦ç´„æ©Ÿèƒ½ã®å®Ÿè£…
"""

import os
import json
import time
import hashlib
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
import structlog

import psycopg2
from psycopg2.extras import RealDictCursor

# æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆè»½é‡åŒ–ç‰ˆï¼‰
try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    np = None

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    SentenceTransformer = None

import google.generativeai as genai
from google.oauth2.service_account import Credentials
import gspread

from .config import Config
from .utils import normalize_text

logger = structlog.get_logger(__name__)


class RAGService:
    """RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚µãƒ¼ãƒ“ã‚¹"""

    def __init__(self):
        """åˆæœŸåŒ–"""
        try:
            print("=" * 60)
            print("ğŸ“ RAGServiceã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("RAGServiceã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            self.embedding_model = None
            self.db_connection = None
            self.is_enabled = False

            # è¨­å®šã®èª­ã¿è¾¼ã¿
            self.gemini_api_key = os.getenv('GEMINI_API_KEY')
            self.database_url = os.getenv('DATABASE_URL')
            self.embedding_model_name = os.getenv('EMBEDDING_MODEL', 'sentence-transformers/all-MiniLM-L6-v2')
            self.vector_dimension = int(os.getenv('VECTOR_DIMENSION', '384'))
            self.similarity_threshold = float(os.getenv('SIMILARITY_THRESHOLD', '0.6'))
            self.gemini_model = None

            print(f"âœ… GEMINI_API_KEYè¨­å®š: {'ã‚ã‚Š' if self.gemini_api_key else 'ãªã—'}")
            print(f"âœ… DATABASE_URLè¨­å®š: {'ã‚ã‚Š' if self.database_url else 'ãªã—'}")
            logger.warning("RAGServiceã®è¨­å®šã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            # ã‚·ãƒ³ãƒ—ãƒ«ãªåˆæœŸåŒ–ãƒ­ã‚¸ãƒƒã‚¯
            self._initialize_rag_service()

            # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
            print(f"ğŸ¯ RAGServiceåˆæœŸåŒ–å®Œäº†: is_enabled={self.is_enabled}")
            print(f"ğŸ¯ Geminiãƒ¢ãƒ‡ãƒ«: {self.gemini_model is not None}")
            print(f"ğŸ¯ DBæ¥ç¶š: {self.db_connection is not None}")
            print("=" * 60)
            logger.warning(f"RAGServiceåˆæœŸåŒ–å®Œäº†: is_enabled={self.is_enabled}")

        except Exception as e:
            print(f"âŒ RAGServiceã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error("RAGServiceã®åˆæœŸåŒ–ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            self.is_enabled = False

    def _initialize_rag_service(self):
        """RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ï¼ˆã‚·ãƒ³ãƒ—ãƒ«ç‰ˆï¼‰"""
        try:
            print("ğŸ”§ RAGã‚µãƒ¼ãƒ“ã‚¹ã®å†…éƒ¨åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®åˆæœŸåŒ–ã‚’è©¦è¡Œ
            print("ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è©¦è¡Œã—ã¦ã„ã¾ã™...")
            database_success = self._try_database_connection()
            print(f"ğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®çµæœ: {database_success}")
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã®çµæœ: {database_success}")

            if database_success:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸå ´åˆã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–
                print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸãŸã‚ã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒæˆåŠŸã—ãŸãŸã‚ã€å®Œå…¨RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                self._initialize_full_rag()
            else:
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸå ´åˆã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–
                print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸãŸã‚ã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                logger.warning("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒå¤±æ•—ã—ãŸãŸã‚ã€ä»£æ›¿RAGæ©Ÿèƒ½ã‚’åˆæœŸåŒ–ã—ã¾ã™")
                self._initialize_fallback_rag()

        except Exception as e:
            print(f"âŒ RAGã‚µãƒ¼ãƒ“ã‚¹ã®å†…éƒ¨åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error("RAGã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e))
            self.is_enabled = False

    def _initialize_fallback_rag(self):
        """ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ï¼ˆpgvectorãªã—ï¼‰"""
        try:
            print("ğŸ”§ ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")
            logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã‚’é–‹å§‹ã—ã¾ã™")

            # Gemini APIã®ã¿ã‚’ä½¿ç”¨ã—ãŸRAGæ©Ÿèƒ½
            if self.gemini_api_key:
                print("ğŸ”‘ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
                genai.configure(api_key=self.gemini_api_key)

                # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ã€ç›´æ¥ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆé«˜é€ŸåŒ–ï¼‰
                try:
                    # gemini-2.0-flash-expã‚’ç›´æ¥ä½¿ç”¨ï¼ˆãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã¯é…ã„ã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼‰
                    print("ğŸ¤– Geminiãƒ¢ãƒ‡ãƒ« 'gemini-2.0-flash-exp' ã‚’åˆæœŸåŒ–ã—ã¦ã„ã¾ã™...")
                    self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-exp')
                    print("âœ… RAG: gemini-2.0-flash-expã‚’ä½¿ç”¨ã—ã¾ã™")
                    logger.info("RAG: gemini-2.0-flash-expã‚’ä½¿ç”¨ã—ã¾ã™")

                except Exception as model_error:
                    print(f"âŒ RAG: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {model_error}")
                    logger.error("RAG: ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(model_error))
                    self.gemini_model = None
                    logger.warning("RAG: Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ")
                    self.is_enabled = False
                    return

                print("âœ… ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")
                self.is_enabled = True
                print(f"ğŸ¯ is_enabled ã‚’ True ã«è¨­å®šã—ã¾ã—ãŸ")
            else:
                print("âŒ Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                logger.warning("Gemini APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
                self.is_enabled = False
        except Exception as e:
            print(f"âŒ ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            logger.error("ä»£æ›¿RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e))
            logger.warning("ä»£æ›¿RAGæ©Ÿèƒ½ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¾ã™ã€‚åŸºæœ¬æ©Ÿèƒ½ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")
            self.is_enabled = False

    def _try_database_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’è©¦è¡Œï¼ˆæˆåŠŸ/å¤±æ•—ã‚’è¿”ã™ï¼‰"""
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šä»˜ãã§æ¥ç¶šï¼ˆ5ç§’ï¼‰
            self.db_connection = psycopg2.connect(
                self.database_url,
                connect_timeout=5
            )
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºç«‹ã—ã¾ã—ãŸ")
            
            # pgvectoræ‹¡å¼µã®ç¢ºèªï¼ˆç°¡ç•¥ç‰ˆï¼‰
            with self.db_connection.cursor() as cursor:
                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®ç¢ºèªï¼ˆè©³ç´°ãªãƒã‚§ãƒƒã‚¯ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¦é«˜é€ŸåŒ–ï¼‰
                cursor.execute("SELECT * FROM pg_available_extensions WHERE name = 'vector';")
                available_extensions = cursor.fetchall()

                if not available_extensions:
                    logger.warning("pgvectoræ‹¡å¼µæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ä»£æ›¿RAGãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
                    return False

                # pgvectoræ‹¡å¼µæ©Ÿèƒ½ã®æœ‰åŠ¹åŒ–ã‚’è©¦è¡Œ
                cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
                self.db_connection.commit()
                logger.info("pgvectoræ‹¡å¼µæ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã—ã¾ã—ãŸ")
            
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ
            self.create_tables()
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒç¢ºç«‹ã•ã‚Œã¾ã—ãŸ")
            logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨pgvectorã®ä¸¡æ–¹ãŒæˆåŠŸã—ãŸãŸã‚Trueã‚’è¿”ã—ã¾ã™")
            return True
            
        except Exception as e:
            logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e))
            self.db_connection = None
            return False

    def _initialize_full_rag(self):
        """å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–"""
        try:
            # Embeddingãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
            if SENTENCE_TRANSFORMERS_AVAILABLE and NUMPY_AVAILABLE:
                logger.info(f"Embeddingãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™: {self.embedding_model_name}")
                self.embedding_model = SentenceTransformer(self.embedding_model_name)
                logger.info("Embeddingãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸ")
            else:
                logger.error("sentence-transformersã¾ãŸã¯numpyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                raise ImportError("sentence-transformersã¾ãŸã¯numpyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")

            # Gemini APIã®åˆæœŸåŒ–
            if self.gemini_api_key:
                genai.configure(api_key=self.gemini_api_key)

                # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‚’ç¢ºèª
                try:
                    models = genai.list_models()
                    available_models = [model.name for model in models if 'generateContent' in model.supported_generation_methods]
                    logger.info(f"RAGåˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«: {available_models[:5]}")  # æœ€åˆã®5ã¤ã®ã¿ãƒ­ã‚°

                    # åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠï¼ˆ2.0ã‚’å„ªå…ˆï¼‰
                    if 'models/gemini-2.0-flash-001' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-2.0-flash-001')
                        logger.info("RAG: gemini-2.0-flash-001ã‚’ä½¿ç”¨ã—ã¾ã™")
                    elif 'models/gemini-flash-latest' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-flash-latest')
                        logger.info("RAG: gemini-flash-latestã‚’ä½¿ç”¨ã—ã¾ã™")
                    elif 'models/gemini-2.5-flash' in available_models:
                        self.gemini_model = genai.GenerativeModel('gemini-2.5-flash')
                        logger.info("RAG: gemini-2.5-flashã‚’ä½¿ç”¨ã—ã¾ã™")
                    else:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                        self.gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')
                        logger.info("RAG: gemini-1.5-flash-latestã‚’ä½¿ç”¨ã—ã¾ã™ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")

                except Exception as model_error:
                    logger.warning("ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™", error=str(model_error))
                    self.gemini_model = genai.GenerativeModel('gemini-1.5-flash-latest')

                logger.info("Gemini APIã‚’åˆæœŸåŒ–ã—ã¾ã—ãŸ")

            self.is_enabled = True
            logger.info("å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

        except Exception as e:
            logger.error("å®Œå…¨RAGæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", error=str(e), exc_info=True)
            self.is_enabled = False

    def create_tables(self):
        """å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆ"""
        if not self.db_connection:
            logger.error("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãŒã‚ã‚Šã¾ã›ã‚“")
            return False
        
        try:
            with self.db_connection.cursor() as cursor:
                # æ–‡æ›¸ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS documents (
                        id SERIAL PRIMARY KEY,
                        source_type VARCHAR(50) NOT NULL,
                        source_id VARCHAR(100) NOT NULL,
                        title TEXT,
                        content TEXT NOT NULL,
                        chunk_index INTEGER DEFAULT 0,
                        metadata JSONB,
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """)
                
                # ãƒ™ã‚¯ãƒˆãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS document_embeddings (
                        id SERIAL PRIMARY KEY,
                        document_id INTEGER REFERENCES documents(id) ON DELETE CASCADE,
                        embedding vector(%s),
                        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                    );
                """, (self.vector_dimension,))
                
                # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
                cursor.execute("""
                    CREATE INDEX IF NOT EXISTS idx_document_embeddings_vector 
                    ON document_embeddings USING ivfflat (embedding vector_cosine_ops);
                """)
                
                self.db_connection.commit()
                logger.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸ")
                return True
                
        except Exception as e:
            logger.error("ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return False

    def add_document(self, source_type: str, source_id: str, title: str, content: str, metadata: Dict[str, Any] = None) -> bool:
        """æ–‡æ›¸ã‚’è¿½åŠ """
        if not self.is_enabled:
            logger.warning("RAGServiceãŒç„¡åŠ¹ã§ã™")
            return False

        # ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã®å ´åˆã€æ–‡æ›¸è¿½åŠ ã¯åˆ©ç”¨ã§ããªã„
        if not self.db_connection or not self.embedding_model:
            logger.info("ä»£æ›¿RAGæ©Ÿèƒ½ã§ã¯æ–‡æ›¸è¿½åŠ ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆãƒ™ã‚¯ãƒˆãƒ«DBæœªæ¥ç¶šï¼‰")
            return False

        try:
            # æ–‡æ›¸ã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²
            chunks = self._split_text(content)
            
            with self.db_connection.cursor() as cursor:
                for i, chunk in enumerate(chunks):
                    # æ–‡æ›¸ã‚’ä¿å­˜
                    cursor.execute("""
                        INSERT INTO documents (source_type, source_id, title, content, chunk_index, metadata)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        RETURNING id;
                    """, (source_type, source_id, title, chunk, i, json.dumps(metadata or {})))
                    
                    document_id = cursor.fetchone()[0]
                    
                    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
                    embedding = self._generate_embedding(chunk)
                    
                    # ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä¿å­˜
                    # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
                    embedding_str = '[' + ','.join(map(str, embedding.tolist())) + ']'
                    cursor.execute("""
                        INSERT INTO document_embeddings (document_id, embedding)
                        VALUES (%s, %s::vector);
                    """, (document_id, embedding_str))
                
                self.db_connection.commit()
                logger.info(f"æ–‡æ›¸ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {source_type}/{source_id}")
                return True
                
        except Exception as e:
            logger.error("æ–‡æ›¸è¿½åŠ ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return False

    def search_similar_documents(self, query: str, limit: int = 3) -> List[Dict[str, Any]]:
        """é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢"""
        print(f"ğŸ” search_similar_documents å‘¼ã³å‡ºã—: query='{query}'")
        logger.info(f"search_similar_documents å‘¼ã³å‡ºã—: query='{query}'")

        if not self.is_enabled:
            print("âŒ RAGServiceãŒç„¡åŠ¹ã§ã™")
            logger.warning("RAGServiceãŒç„¡åŠ¹ã§ã™")
            return []

        # ä»£æ›¿RAGæ©Ÿèƒ½ï¼ˆGeminiã®ã¿ï¼‰ã®å ´åˆã€ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã¯åˆ©ç”¨ã§ããªã„
        if not self.db_connection or not self.embedding_model:
            print(f"âš ï¸ DBæ¥ç¶š: {self.db_connection is not None}, Embeddingãƒ¢ãƒ‡ãƒ«: {self.embedding_model is not None}")
            logger.warning(f"ä»£æ›¿RAGæ©Ÿèƒ½ãƒã‚§ãƒƒã‚¯: DBæ¥ç¶š={self.db_connection is not None}, Embeddingãƒ¢ãƒ‡ãƒ«={self.embedding_model is not None}")
            return []

        try:
            print("âœ… ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™")
            # ã‚¯ã‚¨ãƒªã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
            query_embedding = self._generate_embedding(query)
            print(f"âœ… ã‚¯ã‚¨ãƒªã®Embeddingã‚’ç”Ÿæˆã—ã¾ã—ãŸ: shape={query_embedding.shape if hasattr(query_embedding, 'shape') else 'N/A'}")
            
            with self.db_connection.cursor(cursor_factory=RealDictCursor) as cursor:
                # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’æ–‡å­—åˆ—å½¢å¼ã«å¤‰æ›
                embedding_str = '[' + ','.join(map(str, query_embedding.tolist())) + ']'

                # é¡ä¼¼åº¦æ¤œç´¢
                cursor.execute("""
                    SELECT
                        d.id,
                        d.source_type,
                        d.source_id,
                        d.title,
                        d.content,
                        d.metadata,
                        1 - (de.embedding <=> %s::vector) as similarity
                    FROM documents d
                    JOIN document_embeddings de ON d.id = de.document_id
                    WHERE 1 - (de.embedding <=> %s::vector) > %s
                    ORDER BY similarity DESC
                    LIMIT %s;
                """, (embedding_str, embedding_str, self.similarity_threshold, limit))
                
                results = cursor.fetchall()
                print(f"âœ… DBæ¤œç´¢çµæœ: {len(results)}ä»¶")

                # è¾æ›¸å½¢å¼ã«å¤‰æ›
                documents = []
                for row in results:
                    documents.append({
                        'id': row['id'],
                        'source_type': row['source_type'],
                        'source_id': row['source_id'],
                        'title': row['title'],
                        'content': row['content'],
                        'metadata': row['metadata'],
                        'similarity': float(row['similarity'])
                    })

                print(f"ğŸ¯ é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¾ã—ãŸ: {len(documents)}ä»¶")
                logger.info(f"é¡ä¼¼æ–‡æ›¸ã‚’æ¤œç´¢ã—ã¾ã—ãŸ: {len(documents)}ä»¶")
                return documents

        except Exception as e:
            print(f"âŒ é¡ä¼¼æ–‡æ›¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            logger.error("é¡ä¼¼æ–‡æ›¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return []

    def generate_answer(self, query: str, context: str = "") -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«åŸºã¥ã„ã¦å›ç­”ã‚’ç”Ÿæˆ"""
        if not self.gemini_api_key or not self.gemini_model:
            logger.warning("Gemini APIã‚­ãƒ¼ã¾ãŸã¯ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚AIå›ç­”ç”Ÿæˆæ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚"
        
        try:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
            prompt = self._build_prompt(query, context)
            
            # Gemini APIã‚’å‘¼ã³å‡ºã—
            response = self.gemini_model.generate_content(
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=1000,
                    temperature=0.7,
                )
            )
            
            answer = response.text
            logger.info("Gemini AIå›ç­”ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            return answer
            
        except Exception as e:
            logger.error("Gemini AIå›ç­”ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ", error=str(e))
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚"

    def _split_text(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²"""
        if len(text) <= chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + chunk_size
            
            # æ–‡ã®å¢ƒç•Œã§åˆ†å‰²
            if end < len(text):
                # æœ€å¾Œã®å¥ç‚¹ã‚’æ¢ã™
                last_period = text.rfind('ã€‚', start, end)
                if last_period > start:
                    end = last_period + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            start = end - overlap
            if start >= len(text):
                break
        
        return chunks

    def _generate_embedding(self, text: str):
        """ãƒ†ã‚­ã‚¹ãƒˆã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        if not NUMPY_AVAILABLE:
            raise ValueError("numpyãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚è»½é‡åŒ–ç‰ˆã§ã¯ç„¡åŠ¹åŒ–ã•ã‚Œã¦ã„ã¾ã™")
        
        if not self.embedding_model:
            raise ValueError("Embeddingãƒ¢ãƒ‡ãƒ«ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’æ­£è¦åŒ–
        normalized_text = normalize_text(text)
        
        # åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ
        embedding = self.embedding_model.encode(normalized_text)
        
        return embedding

    def _build_context(self, documents: List[Dict[str, Any]]) -> str:
        """ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        context_parts = []
        
        for i, doc in enumerate(documents, 1):
            context_parts.append(f"ã€æ–‡æ›¸{i}ã€‘")
            context_parts.append(f"ã‚¿ã‚¤ãƒˆãƒ«: {doc['title']}")
            context_parts.append(f"å†…å®¹: {doc['content']}")
            context_parts.append(f"é¡ä¼¼åº¦: {doc['similarity']:.3f}")
            context_parts.append("")
        
        return "\n".join(context_parts)

    def _build_prompt(self, query: str, context: str) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        if context:
            return f"""
è³ªå•: {query}

ä»¥ä¸‹ã®æƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ï¼š

{context}

å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ï¼š
1. çµè«–
2. æ‰‹é †ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
3. å‚è€ƒæƒ…å ±

æ—¥æœ¬èªã§ã€åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
"""
        else:
            return f"""
è³ªå•: {query}

è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚å‹•ç”»åˆ¶ä½œä¼šç¤¾ã®ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã¨ã—ã¦ã€è¦ªã—ã¿ã‚„ã™ãä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã¯ä»¥ä¸‹ã®å½¢å¼ã§ãŠé¡˜ã„ã—ã¾ã™ï¼š
1. çµè«–
2. æ‰‹é †ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
3. å‚è€ƒæƒ…å ±

æ—¥æœ¬èªã§ã€åˆ†ã‹ã‚Šã‚„ã™ãå›ç­”ã—ã¦ãã ã•ã„ã€‚
"""

    def health_check(self) -> bool:
        """RAGã‚µãƒ¼ãƒ“ã‚¹ã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯"""
        return self.is_enabled and self.gemini_model is not None
